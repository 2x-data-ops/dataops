{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file input\n",
    "# rename this file\n",
    "file_name = 'bquxjob_3c3299dc_191733d2362.csv'\n",
    "\n",
    "# file source by default should be downloaded to Downloads folder\n",
    "# please check the user path\n",
    "csv_file_path = f\"C:\\\\Users\\\\MeorHasyim\\\\Downloads\\\\{file_name}\"\n",
    "\n",
    "df_csv = pd.read_csv(csv_file_path)\n",
    "\n",
    "# extract ddl statement from csv\n",
    "ddl = df_csv['ddl'][0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recursively flatten STRUCT columns with correct prefixing\n",
    "def extract_columns_from_ddl(ddl, prefix=\"\"):\n",
    "    columns = []\n",
    "    data_types = []\n",
    "    \n",
    "    # Correctly match STRUCT<...> and handle potential trailing characters\n",
    "    matches = re.findall(r'(\\w+)\\s+(STRUCT<[^>]+>|[\\w]+)', ddl)\n",
    "    \n",
    "    for match in matches:\n",
    "        column_name, column_type = match\n",
    "        full_column_name = f\"{prefix}.{column_name}\" if prefix else column_name\n",
    "\n",
    "        if 'STRUCT<' in column_type:\n",
    "            # Extract the inner STRUCT fields\n",
    "            inner_struct = column_type[column_type.find('<') + 1: column_type.rfind('>')]\n",
    "            nested_columns, nested_types = extract_columns_from_ddl(inner_struct, prefix=full_column_name)\n",
    "            columns.extend(nested_columns)\n",
    "            data_types.extend(nested_types)\n",
    "        else:\n",
    "            # Add simple column name and its data type\n",
    "            columns.append(full_column_name)\n",
    "            data_types.append(column_type.strip('>,'))\n",
    "    \n",
    "    return columns, data_types\n",
    "\n",
    "# Extract columns and data types from the DDL statement\n",
    "column_names, data_types = extract_columns_from_ddl(ddl)\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'column_name': column_names,\n",
    "    'data_type': data_types\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# download path\n",
    "downloads_folder = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "\n",
    "# name the csv output name\n",
    "csv_file_path = os.path.join(downloads_folder, 'erer.csv')\n",
    "\n",
    "# output syntax\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"CSV file saved to: {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
